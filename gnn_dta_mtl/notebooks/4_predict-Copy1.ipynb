{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a846f1-38ca-44c4-96ea-8242e63a8cdd",
   "metadata": {},
   "source": [
    "# Inference simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5633a39-1af1-4f28-9b62-170ffd48eb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "class DTAPredictor:\n",
    "    \"\"\"Simple predictor for drug-target affinity.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, config_path=None, device='cuda'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_path: Path to saved model checkpoint\n",
    "            config_path: Path to config file (optional)\n",
    "            device: Device to run on\n",
    "        \"\"\"\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load config\n",
    "        if config_path and Path(config_path).exists():\n",
    "            with open(config_path, 'r') as f:\n",
    "                self.config = json.load(f)\n",
    "        else:\n",
    "            # Default config\n",
    "            self.config = {\n",
    "                'task_cols': ['pKi', 'pEC50', 'pKd', 'pIC50', 'pKd (Wang, FEP)', 'potency'],\n",
    "                'model_config': {\n",
    "                    'prot_emb_dim': 1280,\n",
    "                    'prot_gcn_dims': [128, 256, 256],\n",
    "                    'prot_fc_dims': [1024, 128],\n",
    "                    'drug_node_in_dim': [66, 1],\n",
    "                    'drug_node_h_dims': [128, 64],\n",
    "                    'drug_edge_in_dim': [16, 1],\n",
    "                    'drug_edge_h_dims': [32, 1],\n",
    "                    'drug_fc_dims': [1024, 128],\n",
    "                    'mlp_dims': [1024, 512],\n",
    "                    'mlp_dropout': 0.25\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Load model\n",
    "        \n",
    "        self.model = MTL_DTAModel(\n",
    "            task_names=self.config['task_cols'],\n",
    "            **self.config['model_config']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Load weights\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            self.model.load_state_dict(checkpoint)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Initialize processors\n",
    "        self._init_processors()\n",
    "    \n",
    "    def _init_processors(self):\n",
    "        \"\"\"Initialize standardization and featurization.\"\"\"\n",
    "        from rdkit import Chem\n",
    "        from rdkit.Chem import AllChem\n",
    "        from Bio.PDB import PDBParser\n",
    "        self.pdb_parser = PDBParser(QUIET=True)\n",
    "        \n",
    "    def predict(self, protein_ligand_pairs):\n",
    "        \"\"\"\n",
    "        Predict affinities for protein-ligand pairs.\n",
    "        \n",
    "        Args:\n",
    "            protein_ligand_pairs: List of tuples (protein_path, ligand_path) or\n",
    "                                 DataFrame with 'protein_path' and 'ligand_path' columns\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with predictions for each task\n",
    "        \"\"\"\n",
    "        # Convert to DataFrame if needed\n",
    "        if isinstance(protein_ligand_pairs, list):\n",
    "            df = pd.DataFrame(protein_ligand_pairs, \n",
    "                            columns=['protein_path', 'ligand_path'])\n",
    "        else:\n",
    "            df = protein_ligand_pairs.copy()\n",
    "        \n",
    "        # Process and predict\n",
    "        predictions = []\n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Predicting\"):\n",
    "            try:\n",
    "                # Featurize\n",
    "                drug_graph = self._featurize_drug(row['ligand_path'])\n",
    "                prot_graph = self._featurize_protein(row['protein_path'])\n",
    "                \n",
    "                # Create batch\n",
    "                \n",
    "\n",
    "                drug_batch = Batch.from_data_list([drug_graph]).to(self.device)\n",
    "                prot_batch = Batch.from_data_list([prot_graph]).to(self.device)\n",
    "                \n",
    "                # Predict\n",
    "                with torch.no_grad():\n",
    "                    pred = self.model(drug_batch, prot_batch)\n",
    "                    pred = pred.cpu().numpy()[0]  # Get first (only) batch item\n",
    "                \n",
    "                # Store predictions\n",
    "                pred_dict = {task: pred[i] for i, task in enumerate(self.config['task_cols'])}\n",
    "                predictions.append(pred_dict)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {idx}: {e}\")\n",
    "                pred_dict = {task: np.nan for task in self.config['task_cols']}\n",
    "                predictions.append(pred_dict)\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results_df = pd.DataFrame(predictions)\n",
    "        results_df = pd.concat([df[['protein_path', 'ligand_path']], results_df], axis=1)\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def _featurize_drug(self, sdf_path):\n",
    "        \"\"\"Quick drug featurization.\"\"\"\n",
    "        import torch_geometric\n",
    "        from rdkit import Chem\n",
    "        import torch_cluster\n",
    "        \n",
    "        mol = Chem.MolFromMolFile(sdf_path)\n",
    "        if mol is None:\n",
    "            raise ValueError(f\"Could not read molecule from {sdf_path}\")\n",
    "        \n",
    "        # Get coordinates\n",
    "        conf = mol.GetConformer()\n",
    "        coords = torch.tensor(conf.GetPositions(), dtype=torch.float32)\n",
    "        \n",
    "        # Simple atom features (simplified)\n",
    "        atom_features = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            features = [\n",
    "                atom.GetAtomicNum(),\n",
    "                atom.GetDegree(),\n",
    "                atom.GetTotalNumHs(),\n",
    "                int(atom.GetIsAromatic())\n",
    "            ]\n",
    "            atom_features.append(features)\n",
    "        \n",
    "        atom_features = torch.tensor(atom_features, dtype=torch.float32)\n",
    "        \n",
    "        # Create edges (radius graph)\n",
    "        edge_index = torch_cluster.radius_graph(coords, r=4.5)\n",
    "        \n",
    "        # Create minimal graph\n",
    "        data = torch_geometric.data.Data(\n",
    "            x=coords,\n",
    "            edge_index=edge_index,\n",
    "            node_s=atom_features,\n",
    "            node_v=coords.unsqueeze(1),\n",
    "            edge_s=torch.ones(edge_index.size(1), 16),  # Dummy edge features\n",
    "            edge_v=torch.ones(edge_index.size(1), 1, 3)  # Dummy edge vectors\n",
    "        )\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def _featurize_protein(self, pdb_path):\n",
    "        \"\"\"Quick protein featurization.\"\"\"\n",
    "        import torch_geometric\n",
    "        import torch_cluster\n",
    "        \n",
    "        # Parse PDB\n",
    "        structure = self.pdb_parser.get_structure('protein', pdb_path)\n",
    "        \n",
    "        # Get CA coordinates\n",
    "        ca_coords = []\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                for residue in chain:\n",
    "                    if 'CA' in residue:\n",
    "                        ca_coords.append(residue['CA'].coord)\n",
    "                if ca_coords:  # Use first chain only\n",
    "                    break\n",
    "            break\n",
    "        \n",
    "        coords = torch.tensor(ca_coords, dtype=torch.float32)\n",
    "        \n",
    "        # Create edges\n",
    "        edge_index = torch_cluster.radius_graph(coords, r=8.0)\n",
    "        \n",
    "        # Dummy features\n",
    "        seq_len = len(coords)\n",
    "        seq = torch.zeros(seq_len, dtype=torch.long)  # Dummy sequence\n",
    "        node_s = torch.randn(seq_len, 6)  # Dummy dihedral features\n",
    "        node_v = torch.randn(seq_len, 3, 3)  # Dummy orientations\n",
    "        seq_emb = torch.randn(seq_len, 1280)  # Dummy ESM embeddings\n",
    "        \n",
    "        # Create graph\n",
    "        data = torch_geometric.data.Data(\n",
    "            x=coords,\n",
    "            seq=seq,\n",
    "            edge_index=edge_index,\n",
    "            node_s=node_s,\n",
    "            node_v=node_v,\n",
    "            edge_s=torch.randn(edge_index.size(1), 39),\n",
    "            edge_v=torch.randn(edge_index.size(1), 1, 3),\n",
    "            seq_emb=seq_emb\n",
    "        )\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "# ============ SIMPLE USAGE ============\n",
    "\n",
    "def predict_affinity(\n",
    "    model_path,\n",
    "    protein_ligand_pairs,\n",
    "    output_path=None,\n",
    "    device='cuda'\n",
    "):\n",
    "    \"\"\"\n",
    "    Simple function to predict affinities.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to trained model\n",
    "        protein_ligand_pairs: List of (protein_pdb, ligand_sdf) or DataFrame\n",
    "        output_path: Optional path to save predictions\n",
    "        device: Device to use\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions\n",
    "    \"\"\"\n",
    "    # Initialize predictor\n",
    "    predictor = DTAPredictor(model_path, device=device)\n",
    "    \n",
    "    # Predict\n",
    "    results = predictor.predict(protein_ligand_pairs)\n",
    "    \n",
    "    # Save if requested\n",
    "    if output_path:\n",
    "        results.to_csv(output_path, index=False)\n",
    "        print(f\"Predictions saved to {output_path}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a05b666-f7b6-4d96-8382-89e903a7fd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51dc48d7-e99e-43a7-90d5-cc3a4e09e43f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB import MMCIFParser, PDBIO, Select\n",
    "\n",
    "class ProteinSelect(Select):\n",
    "    def accept_residue(self, residue):\n",
    "        return residue.get_id()[0] == ' '\n",
    "\n",
    "    \n",
    "class LigandSelect(Select):\n",
    "    def accept_residue(self, residue):\n",
    "        return residue.get_id()[0] != ' '\n",
    "        \n",
    "def check_files_exist_and_valid(protein_path, ligand_path, min_size_bytes=50):\n",
    "    \"\"\"Check if both protein and ligand files exist and are valid\"\"\"\n",
    "    try:\n",
    "        if not (os.path.exists(protein_path) and os.path.exists(ligand_path)):\n",
    "            return False\n",
    "        \n",
    "        protein_size = os.path.getsize(protein_path)\n",
    "        ligand_size = os.path.getsize(ligand_path)\n",
    "        \n",
    "        if protein_size < min_size_bytes or ligand_size < min_size_bytes:\n",
    "            return False\n",
    "            \n",
    "        # Quick content validation\n",
    "        try:\n",
    "            with open(protein_path, 'r') as f:\n",
    "                first_line = f.readline().strip()\n",
    "                if not (first_line.startswith(('ATOM', 'HETATM', 'MODEL', 'HEADER'))):\n",
    "                    return False\n",
    "            \n",
    "            with open(ligand_path, 'r') as f:\n",
    "                content = f.read(100)\n",
    "                if len(content.strip()) < 10:\n",
    "                    return False\n",
    "                    \n",
    "        except Exception:\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def process_single(input_path, protein_dir, ligand_dir):\n",
    "    \"\"\"Process a single CIF file\"\"\"\n",
    "    input_filename = os.path.basename(input_path)\n",
    "    \n",
    "    # Parse CIF file\n",
    "    if input_path.endswith(\".cif\"):\n",
    "        parser = MMCIFParser(QUIET=True)\n",
    "        pdb_filename = input_filename.replace(\".cif\", \".pdb\")\n",
    "        sdf_filename = input_filename.replace(\".cif\", \".sdf\")\n",
    "\n",
    "    if input_path.endswith(\".pdb\"):\n",
    "        parser = PDBParser(QUIET=True)\n",
    "        pdb_filename = input_filename.replace(\".pdb\", \".pdb\")\n",
    "        sdf_filename = input_filename.replace(\".pdb\", \".sdf\")\n",
    "\n",
    "        \n",
    "    \n",
    "    pdb_path = os.path.join(str(protein_dir), str(pdb_filename))\n",
    "    sdf_path = os.path.join(str(ligand_dir), str(sdf_filename))\n",
    "    \n",
    "    # Skip if files already exist and are valid\n",
    "    if check_files_exist_and_valid(pdb_path, sdf_path):\n",
    "        return {\n",
    "            'protein_path': pdb_path,\n",
    "            'ligand_path': sdf_path,\n",
    "            'status': 'already_exists',\n",
    "            'success': True\n",
    "        }\n",
    "    \n",
    "    # Clean up any partially created files\n",
    "    for path in [pdb_path, sdf_path]:\n",
    "        if os.path.exists(path) :\n",
    "            try:\n",
    "                os.remove(path)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    try:\n",
    "        # Parse CIF file\n",
    "        structure = parser.get_structure(\"complex\", input_path)\n",
    "        \n",
    "        # Write protein PDB\n",
    "        io = PDBIO()\n",
    "        io.set_structure(structure)\n",
    "        io.save(pdb_path, select=ProteinSelect())\n",
    "        \n",
    "        # Write ligand to temporary PDB first\n",
    "        ligand_temp_pdb = sdf_path.replace(\".sdf\", \"_temp.pdb\")\n",
    "        io.save(ligand_temp_pdb, select=LigandSelect())\n",
    "        \n",
    "        # Convert ligand PDB to SDF using RDKit\n",
    "        mol = rdmolfiles.MolFromPDBFile(ligand_temp_pdb, removeHs=False)\n",
    "        \n",
    "        if mol is not None:\n",
    "            writer = Chem.SDWriter(sdf_path)\n",
    "            writer.write(mol)\n",
    "            writer.close()\n",
    "            \n",
    "            # Clean up temp file\n",
    "            if os.path.exists(ligand_temp_pdb):\n",
    "                os.remove(ligand_temp_pdb)\n",
    "            \n",
    "            # Final validation\n",
    "            if check_files_exist_and_valid(pdb_path, sdf_path):\n",
    "                return {\n",
    "                    'protein_path': pdb_path,\n",
    "                    'ligand_path': sdf_path,\n",
    "                    'status': 'converted_successfully',\n",
    "                    'success': True\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'protein_path': pdb_path,\n",
    "                    'ligand_path': sdf_path,\n",
    "                    'status': 'validation_failed',\n",
    "                    'success': False\n",
    "                }\n",
    "        else:\n",
    "            # RDKit conversion failed\n",
    "            if os.path.exists(ligand_temp_pdb):\n",
    "                os.remove(ligand_temp_pdb)\n",
    "            return {\n",
    "                'protein_path': pdb_path,\n",
    "                'ligand_path': sdf_path,\n",
    "                'status': 'rdkit_failed',\n",
    "                'success': False\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Clean up any partial files\n",
    "        for path in [pdb_path, sdf_path]:\n",
    "            if os.path.exists(path):\n",
    "                try:\n",
    "                    os.remove(path)\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "        return {\n",
    "            'protein_path': pdb_path,\n",
    "            'ligand_path': sdf_path,\n",
    "            'status': f'error: {str(e)}',\n",
    "            'success': False\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283453d1-b584-4041-8e65-3f1f6ba7d8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f5e4ed-6057-4c54-aba4-1dbdd4e388c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: Tesla T4\n",
      "Number of GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "# This allows importing the gnn_dta_mtl package\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Import your package - use absolute import instead of relative\n",
    "from gnn_dta_mtl import (\n",
    "    MTL_DTAModel, DTAModel,\n",
    "    MTL_DTA, DTA,\n",
    "    CrossValidator, MTLTrainer,\n",
    "    StructureStandardizer, StructureProcessor, StructureChunkLoader,\n",
    "    ESMEmbedder,\n",
    "    add_molecular_properties_parallel,\n",
    "    compute_ligand_efficiency,\n",
    "    compute_mean_ligand_efficiency,\n",
    "    filter_by_properties,\n",
    "    prepare_mtl_experiment,\n",
    "    build_mtl_dataset, build_mtl_dataset_optimized,\n",
    "    evaluate_model,\n",
    "    plot_results, plot_predictions, create_summary_report,\n",
    "    ExperimentLogger,\n",
    "    save_model, save_results, create_output_dir,\n",
    "    featurize_drug, featurize_protein_graph\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9129b41-b833-4621-90b6-0048786ad57c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Batch\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.SeqUtils import seq1\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "class DTAPredictor:\n",
    "    \"\"\"Simple predictor for drug-target affinity.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, config_path=None, device='cuda', esm_model=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_path: Path to saved model checkpoint\n",
    "            config_path: Path to config file (optional)\n",
    "            device: Device to run on\n",
    "            esm_model: Pre-loaded ESM model (optional)\n",
    "        \"\"\"\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load config\n",
    "        if config_path and Path(config_path).exists():\n",
    "            with open(config_path, 'r') as f:\n",
    "                self.config = json.load(f)\n",
    "        else:\n",
    "            # Default config\n",
    "            self.config = {\n",
    "                'task_cols': ['pKi', 'pEC50', 'pKd', 'pIC50', 'pKd (Wang, FEP)', 'potency'],\n",
    "                'model_config': {\n",
    "                    'prot_emb_dim': 1280,\n",
    "                    'prot_gcn_dims': [128, 256, 256],\n",
    "                    'prot_fc_dims': [1024, 128],\n",
    "                    'drug_node_in_dim': [66, 1],\n",
    "                    'drug_node_h_dims': [128, 64],\n",
    "                    'drug_edge_in_dim': [16, 1],\n",
    "                    'drug_edge_h_dims': [32, 1],\n",
    "                    'drug_fc_dims': [1024, 128],\n",
    "                    'mlp_dims': [1024, 512],\n",
    "                    'mlp_dropout': 0.25\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Load model\n",
    "        self.model = MTL_DTAModel(\n",
    "            task_names=self.config['task_cols'],\n",
    "            **self.config['model_config']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Load weights\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            self.model.load_state_dict(checkpoint)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Initialize ESM model for protein embeddings\n",
    "        if esm_model is not None:\n",
    "            self.esm_model = esm_model\n",
    "            self.tokenizer = None\n",
    "        else:\n",
    "            from transformers import EsmModel, EsmTokenizer\n",
    "            model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
    "            self.tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "            self.esm_model = EsmModel.from_pretrained(model_name)\n",
    "            self.esm_model.eval()\n",
    "            self.esm_model = self.esm_model.to(self.device)\n",
    "        \n",
    "        # Initialize parser\n",
    "        self.parser = PDBParser(QUIET=True)\n",
    "        \n",
    "        print(f\"✓ Model loaded from {model_path}\")\n",
    "        print(f\"✓ Using device: {self.device}\")\n",
    "        \n",
    "    def extract_backbone_coords(self, structure, pdb_id, pdb_path):\n",
    "        \"\"\"Extract backbone coordinates from protein structure (from your code).\"\"\"\n",
    "        coords = {\"N\": [], \"CA\": [], \"C\": [], \"O\": []}\n",
    "        seq = \"\"\n",
    "        \n",
    "        model = structure[0]\n",
    "        \n",
    "        # Find valid chain\n",
    "        valid_chain = None\n",
    "        for chain in model:\n",
    "            for res in chain:\n",
    "                if res.id[0] == ' ':  # Standard amino acid\n",
    "                    valid_chain = chain\n",
    "                    break\n",
    "            if valid_chain:\n",
    "                break\n",
    "        \n",
    "        if valid_chain is None:\n",
    "            return None, None, None\n",
    "        \n",
    "        chain_id = valid_chain.id\n",
    "        \n",
    "        # Extract coordinates and sequence\n",
    "        for res in valid_chain:\n",
    "            if res.id[0] != ' ':  # Skip non-standard residues\n",
    "                continue\n",
    "            \n",
    "            # Get one-letter code\n",
    "            try:\n",
    "                seq += seq1(res.resname)\n",
    "            except:\n",
    "                seq += 'X'  # Unknown residue\n",
    "            \n",
    "            # Get backbone atom coordinates\n",
    "            for atom_name in [\"N\", \"CA\", \"C\", \"O\"]:\n",
    "                if atom_name in res:\n",
    "                    coords[atom_name].append(res[atom_name].coord.tolist())\n",
    "                else:\n",
    "                    coords[atom_name].append([float(\"nan\")] * 3)\n",
    "        \n",
    "        return seq, coords, chain_id\n",
    "    \n",
    "    def get_esm_embedding(self, seq):\n",
    "        \"\"\"Get ESM embedding for sequence (from your code).\"\"\"\n",
    "        if self.tokenizer is None:\n",
    "            from transformers import EsmTokenizer\n",
    "            self.tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "        \n",
    "        inputs = self.tokenizer(seq, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.esm_model(**inputs)\n",
    "            # Remove CLS and EOS tokens\n",
    "            embedding = outputs.last_hidden_state[0, 1:-1]\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def create_protein_structure_dict(self, pdb_path):\n",
    "        \"\"\"Create protein structure dictionary with real ESM embeddings.\"\"\"\n",
    "        pdb_id = os.path.basename(pdb_path).split('.')[0]\n",
    "        \n",
    "        structure = self.parser.get_structure(pdb_id, pdb_path)\n",
    "        seq, coords, chain_id = self.extract_backbone_coords(structure, pdb_id, pdb_path)\n",
    "        \n",
    "        if seq is None:\n",
    "            raise ValueError(f\"No valid chain found in {pdb_path}\")\n",
    "        \n",
    "        # Stack coordinates in order: N, CA, C, O\n",
    "        coords_stacked = []\n",
    "        for i in range(len(coords[\"N\"])):\n",
    "            coord_group = []\n",
    "            for atom in [\"N\", \"CA\", \"C\", \"O\"]:\n",
    "                coord_group.append(coords[atom][i])\n",
    "            coords_stacked.append(coord_group)\n",
    "        \n",
    "        # Get ESM embedding\n",
    "        embedding = self.get_esm_embedding(seq)\n",
    "        \n",
    "        # Save embedding temporarily\n",
    "        with tempfile.NamedTemporaryFile(suffix='.pt', delete=False) as f:\n",
    "            torch.save(embedding.cpu(), f.name)\n",
    "            embed_path = f.name\n",
    "        \n",
    "        structure_dict = {\n",
    "            \"name\": pdb_id,\n",
    "            \"UniProt_id\": \"UNKNOWN\",\n",
    "            \"PDB_id\": pdb_id,\n",
    "            \"chain\": chain_id,\n",
    "            \"seq\": seq,\n",
    "            \"coords\": coords_stacked,\n",
    "            \"embed\": embed_path\n",
    "        }\n",
    "        \n",
    "        return structure_dict\n",
    "    \n",
    "    #def predict(self, protein_ligand_pairs):\n",
    "    #    \"\"\"\n",
    "    #    Predict affinities for protein-ligand pairs.\n",
    "    #    \n",
    "    #    Args:\n",
    "    #        protein_ligand_pairs: List of tuples (protein_path, ligand_path) or\n",
    "    #                             DataFrame with 'protein_path' and 'ligand_path' columns\n",
    "    #    \n",
    "    #    Returns:\n",
    "    #        DataFrame with predictions for each task\n",
    "    #    \"\"\"\n",
    "    #    # Import featurization functions\n",
    "    #    \n",
    "    #    # Convert to DataFrame if needed\n",
    "    #    if isinstance(protein_ligand_pairs, list):\n",
    "    #        df = pd.DataFrame(protein_ligand_pairs, \n",
    "    #                        columns=['protein_path', 'ligand_path'])\n",
    "    #    else:\n",
    "    #        df = protein_ligand_pairs.copy()\n",
    "    #    \n",
    "    #    # Process and predict\n",
    "    #    predictions = []\n",
    "    #    \n",
    "    #    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Predicting\"):\n",
    "    #        try:\n",
    "    #            # Featurize drug\n",
    "    #            drug_graph = featurize_drug(row['ligand_path'])\n",
    "    #            \n",
    "    #            # Create protein structure with real ESM embeddings\n",
    "    #            protein_struct = self.create_protein_structure_dict(row['protein_path'])\n",
    "    #            \n",
    "    #            # Featurize protein\n",
    "    #            prot_graph = featurize_protein_graph(protein_struct)\n",
    "    #            \n",
    "    #            # Batch the data properly\n",
    "    #            drug_batch = Batch.from_data_list([drug_graph]).to(self.device)\n",
    "    #            prot_batch = Batch.from_data_list([prot_graph]).to(self.device)\n",
    "    #            \n",
    "    #            # Predict\n",
    "    #            with torch.no_grad():\n",
    "    #                pred = self.model(drug_batch, prot_batch)\n",
    "    #                pred = pred.cpu().numpy()[0]  # Get first (only) batch item\n",
    "    #            \n",
    "    #            # Store predictions\n",
    "    #            pred_dict = {task: float(pred[i]) for i, task in enumerate(self.config['task_cols'])}\n",
    "    #            predictions.append(pred_dict)\n",
    "    #            \n",
    "    #            # Clean up temp embedding file\n",
    "    #            if os.path.exists(protein_struct['embed']):\n",
    "    #                os.remove(protein_struct['embed'])\n",
    "    #            \n",
    "    #        except Exception as e:\n",
    "    #            print(f\"Error processing {idx} ({row['protein_path']}): {e}\")\n",
    "    #            pred_dict = {task: np.nan for task in self.config['task_cols']}\n",
    "    #            predictions.append(pred_dict)\n",
    "    #    \n",
    "    #    # Create results DataFrame\n",
    "    #    results_df = pd.DataFrame(predictions)\n",
    "    #    results_df = pd.concat([df[['protein_path', 'ligand_path']], results_df], axis=1)\n",
    "    #    \n",
    "    #    return results_df\n",
    "\n",
    "    def predict(self, protein_ligand_pairs):\n",
    "        \"\"\"\n",
    "        Predict affinities for protein-ligand pairs.\n",
    "\n",
    "        Args:\n",
    "            protein_ligand_pairs: List of tuples (protein_path, ligand_path) or\n",
    "                                 DataFrame with 'protein_path' and 'ligand_path' columns\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with predictions for each task\n",
    "        \"\"\"\n",
    "        # Convert to DataFrame if needed\n",
    "        if isinstance(protein_ligand_pairs, list):\n",
    "            df = pd.DataFrame(protein_ligand_pairs, \n",
    "                            columns=['protein_path', 'ligand_path'])\n",
    "        else:\n",
    "            df = protein_ligand_pairs.copy()\n",
    "\n",
    "        # Step 1: Featurize all pairs\n",
    "        drug_graphs = []\n",
    "        prot_graphs = []\n",
    "        valid_indices = []\n",
    "        temp_embed_files = []\n",
    "\n",
    "        print(\"Featurizing all protein-ligand pairs...\")\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Featurizing\"):\n",
    "            try:\n",
    "                # Featurize drug\n",
    "                drug_graph = featurize_drug(row['ligand_path'])\n",
    "\n",
    "                # Create protein structure with real ESM embeddings\n",
    "                protein_struct = self.create_protein_structure_dict(row['protein_path'])\n",
    "                temp_embed_files.append(protein_struct['embed'])\n",
    "\n",
    "                # Featurize protein\n",
    "                prot_graph = featurize_protein_graph(protein_struct)\n",
    "\n",
    "                # Store graphs\n",
    "                drug_graphs.append(drug_graph)\n",
    "                prot_graphs.append(prot_graph)\n",
    "                valid_indices.append(idx)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error featurizing {idx} ({row['protein_path']}): {e}\")\n",
    "\n",
    "        # Step 2: Batch all data\n",
    "        if drug_graphs:\n",
    "            drug_batch = Batch.from_data_list(drug_graphs).to(self.device)\n",
    "            prot_batch = Batch.from_data_list(prot_graphs).to(self.device)\n",
    "\n",
    "            # Step 3: Predict on full batch\n",
    "            print(\"Running batch prediction...\")\n",
    "            with torch.no_grad():\n",
    "                batch_preds = self.model(drug_batch, prot_batch)\n",
    "                batch_preds = batch_preds.cpu().numpy()\n",
    "\n",
    "        # Step 4: Format results\n",
    "        predictions = []\n",
    "        pred_idx = 0\n",
    "\n",
    "        for idx in range(len(df)):\n",
    "            if idx in valid_indices:\n",
    "                # Get predictions for this sample\n",
    "                pred = batch_preds[pred_idx]\n",
    "                pred_dict = {task: float(pred[i]) for i, task in enumerate(self.config['task_cols'])}\n",
    "                pred_idx += 1\n",
    "            else:\n",
    "                # Failed featurization - use NaN\n",
    "                pred_dict = {task: np.nan for task in self.config['task_cols']}\n",
    "\n",
    "            predictions.append(pred_dict)\n",
    "\n",
    "        # Clean up temp embedding files\n",
    "        for embed_file in temp_embed_files:\n",
    "            if os.path.exists(embed_file):\n",
    "                os.remove(embed_file)\n",
    "\n",
    "        # Create results DataFrame\n",
    "        results_df = pd.DataFrame(predictions)\n",
    "        results_df = pd.concat([df[['protein_path', 'ligand_path']], results_df], axis=1)\n",
    "\n",
    "        return results_df\n",
    "\n",
    "def predict_affinity(\n",
    "    model_path,\n",
    "    protein_ligand_pairs,\n",
    "    output_path=None,\n",
    "    device='cuda',\n",
    "    esm_model=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Simple function to predict affinities with real featurization.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to trained model\n",
    "        protein_ligand_pairs: List of (protein_pdb, ligand_sdf) or DataFrame\n",
    "        output_path: Optional path to save predictions\n",
    "        device: Device to use\n",
    "        esm_model: Pre-loaded ESM model (optional, will load if not provided)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions\n",
    "    \"\"\"\n",
    "    # Initialize predictor\n",
    "    predictor = DTAPredictor(model_path, device=device, esm_model=esm_model)\n",
    "    \n",
    "    # Predict\n",
    "    results = predictor.predict(protein_ligand_pairs)\n",
    "    \n",
    "    # Save if requested\n",
    "    if output_path:\n",
    "        results.to_csv(output_path, index=False)\n",
    "        print(f\"Predictions saved to {output_path}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83e09f-1324-4a72-a269-ff734904d81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdd098c7-574f-466e-9bde-19a4545e9828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein_path': '../output/protein/6OH4.pdb',\n",
       " 'ligand_path': '../output/ligand/6OH4.sdf',\n",
       " 'status': 'already_exists',\n",
       " 'success': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete working script\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolfiles\n",
    "\n",
    "protein_dir = Path('../output/protein')\n",
    "ligand_dir = Path('../output/ligand')\n",
    "input_path = '6OH4.pdb'\n",
    "    \n",
    "processed_files = process_single(input_path, protein_dir, ligand_dir)\n",
    "\n",
    "processed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f476600a-a42c-41e1-ac7f-54ff7dc5c851",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ESM model loaded\n",
      "✓ Model loaded from ../output/experiments/gnn_dta_mtl_experiment_20250910_153508/models/final_model.pt\n",
      "✓ Using device: cuda\n",
      "Featurizing all protein-ligand pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing: 100%|██████████| 10/10 [00:38<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch prediction...\n",
      "Predictions saved to affinity_predictions.csv\n",
      "\n",
      "Prediction Results:\n",
      "============================================================\n",
      "\n",
      "Complex 1:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "Complex 2:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "Complex 3:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "Complex 4:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "Complex 5:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "Complex 6:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "Complex 7:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "Complex 8:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "Complex 9:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "Complex 10:\n",
      "  Protein: 6OH4.pdb\n",
      "  Ligand: 6OH4.sdf\n",
      "  Predictions:\n",
      "    pKi: 5.644\n",
      "    pEC50: 6.288\n",
      "    pKd: 6.650\n",
      "    pIC50: 5.907\n",
      "    pKd (Wang, FEP): 0.332\n",
      "    potency: -0.738\n",
      "\n",
      "✓ Predictions complete!\n"
     ]
    }
   ],
   "source": [
    "# Load ESM model once (optional - for efficiency with multiple predictions)\n",
    "from transformers import EsmModel, EsmTokenizer\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# Disable RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "print(\"Loading ESM model...\")\n",
    "model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "esm_model = EsmModel.from_pretrained(model_name)\n",
    "esm_model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    esm_model = esm_model.cuda()\n",
    "print(\"✓ ESM model loaded\")\n",
    "\n",
    "# Now run predictions\n",
    "model_checkpoint = \"../output/experiments/gnn_dta_mtl_experiment_20250910_153508/models/final_model.pt\"\n",
    "\n",
    "# Your test complexes\n",
    "test_complexes = [\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "    ('../output/protein/6OH4.pdb', '../output/ligand/6OH4.sdf'),\n",
    "]\n",
    "\n",
    "# Get predictions with real ESM embeddings\n",
    "predictions = predict_affinity(\n",
    "    model_path=model_checkpoint,\n",
    "    protein_ligand_pairs=test_complexes,\n",
    "    output_path='affinity_predictions.csv',\n",
    "    device='cuda',\n",
    "    esm_model=esm_model  # Pass pre-loaded model\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in predictions.iterrows():\n",
    "    print(f\"\\nComplex {idx+1}:\")\n",
    "    print(f\"  Protein: {Path(row['protein_path']).name}\")\n",
    "    print(f\"  Ligand: {Path(row['ligand_path']).name}\")\n",
    "    print(f\"  Predictions:\")\n",
    "    for task in ['pKi', 'pEC50', 'pKd', 'pIC50', 'pKd (Wang, FEP)', 'potency']:\n",
    "        if task in predictions.columns and not pd.isna(row[task]):\n",
    "            print(f\"    {task}: {row[task]:.3f}\")\n",
    "\n",
    "print(f\"\\n✓ Predictions complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5395a-69ce-487f-82f3-a88fcfdaa2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "458e5789-3e63-45f8-8e15-0ae9015303b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_path</th>\n",
       "      <th>ligand_path</th>\n",
       "      <th>pKi</th>\n",
       "      <th>pEC50</th>\n",
       "      <th>pKd</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>pKd (Wang, FEP)</th>\n",
       "      <th>potency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../output/protein/6OH4.pdb</td>\n",
       "      <td>../output/ligand/6OH4.sdf</td>\n",
       "      <td>5.643721</td>\n",
       "      <td>6.287929</td>\n",
       "      <td>6.650221</td>\n",
       "      <td>5.907095</td>\n",
       "      <td>0.332366</td>\n",
       "      <td>-0.738483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 protein_path                ligand_path       pKi     pEC50  \\\n",
       "0  ../output/protein/6OH4.pdb  ../output/ligand/6OH4.sdf  5.643721  6.287929   \n",
       "\n",
       "        pKd     pIC50  pKd (Wang, FEP)   potency  \n",
       "0  6.650221  5.907095         0.332366 -0.738483  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a0d49-d7cf-4026-84ac-d3ec4b77a386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2b03a-1ac4-4498-9a83-9d4db2f081f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8513d-9e97-437f-a151-30604e00a1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c465bb-388f-4063-b2c2-6da2e385df3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "bioml",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "BioML (Python 3.10)",
   "language": "python",
   "name": "bioml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
